{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "ee5f699b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/haoranhuang/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from processors.cls_sentence import cls_processors as processors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "86453d6c",
            "metadata": {},
            "outputs": [],
            "source": [
                "processor = processors[\"sentence\"]()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "d393cb46",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tools.sentence_data import get_output_data_folder\n",
                "examples = processor.get_train_examples(get_output_data_folder())\n",
                "labels = processor.get_labels()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "f3f749f1",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{\n",
                        "  \"guid\": \"train-0\",\n",
                        "  \"labels\": [\n",
                        "    \"name\"\n",
                        "  ],\n",
                        "  \"words\": [\n",
                        "    \"\\u53f6\",\n",
                        "    \"\\u8001\",\n",
                        "    \"\\u6842\"\n",
                        "  ]\n",
                        "}\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "print(examples[0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "fd33b6ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "from run_sentence_classification import *\n",
                "predict_type = \"softmax\"\n",
                "arg_list = setup_running_env()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "efb6944a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "08/11/2022 07:25:08 - INFO - run_sentence_classification:682 -  device_name is cuda\n",
                        "08/11/2022 07:25:08 - WARNING - run_sentence_classification:692 -  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
                        "08/11/2022 07:25:08 - INFO - run_sentence_classification:704 -  task_name is sentence\n",
                        "08/11/2022 07:25:08 - INFO - run_sentence_classification:715 -  model_type is bert\n",
                        "08/11/2022 07:25:08 - INFO - configuration_utils:120 -  \n",
                        "=============Loading configuration from pretrain. kwargs: {'num_labels': 144, 'loss_type': 'ce', 'cache_dir': '/home/haoranhuang/.cache/torch/transformers'}\n",
                        "08/11/2022 07:25:09 - INFO - configuration_utils:151 -  loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json from cache at /home/haoranhuang/.cache/torch/transformers/8a3b1cfe5da58286e12a0f5d7d182b8d6eca88c08e26c332ee3817548cf7e60a.f12a4f986e43d8b328f5b067a641064d67b91597567a06c7b122d1ca7dfd9741\n",
                        "08/11/2022 07:25:09 - INFO - configuration_utils:171 -  Model config {\n",
                        "  \"architectures\": [\n",
                        "    \"BertForMaskedLM\"\n",
                        "  ],\n",
                        "  \"attention_probs_dropout_prob\": 0.1,\n",
                        "  \"directionality\": \"bidi\",\n",
                        "  \"finetuning_task\": null,\n",
                        "  \"hidden_act\": \"gelu\",\n",
                        "  \"hidden_dropout_prob\": 0.1,\n",
                        "  \"hidden_size\": 768,\n",
                        "  \"initializer_range\": 0.02,\n",
                        "  \"intermediate_size\": 3072,\n",
                        "  \"layer_norm_eps\": 1e-12,\n",
                        "  \"loss_type\": \"ce\",\n",
                        "  \"max_position_embeddings\": 512,\n",
                        "  \"model_type\": \"bert\",\n",
                        "  \"num_attention_heads\": 12,\n",
                        "  \"num_hidden_layers\": 12,\n",
                        "  \"num_labels\": 144,\n",
                        "  \"output_attentions\": false,\n",
                        "  \"output_hidden_states\": false,\n",
                        "  \"output_past\": true,\n",
                        "  \"pad_token_id\": 0,\n",
                        "  \"pooler_fc_size\": 768,\n",
                        "  \"pooler_num_attention_heads\": 12,\n",
                        "  \"pooler_num_fc_layers\": 3,\n",
                        "  \"pooler_size_per_head\": 128,\n",
                        "  \"pooler_type\": \"first_token_transform\",\n",
                        "  \"pruned_heads\": {},\n",
                        "  \"torchscript\": false,\n",
                        "  \"type_vocab_size\": 2,\n",
                        "  \"use_bfloat16\": false,\n",
                        "  \"vocab_size\": 21128\n",
                        "}\n",
                        "\n",
                        "08/11/2022 07:25:09 - INFO - tokenization_utils:282 -  \n",
                        "=============Loading tokenizer from pretrain. kwargs: {'do_lower_case': True, 'cache_dir': '/home/haoranhuang/.cache/torch/transformers'}\n",
                        "08/11/2022 07:25:10 - INFO - tokenization_utils:374 -  loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt from cache at /home/haoranhuang/.cache/torch/transformers/8a0c070123c1f794c42a29c6904beb7c1b8715741e235bee04aca2c7636fc83f.9b42061518a39ca00b8b52059fd2bede8daa613f8a8671500e518a8c29de8c00\n",
                        "08/11/2022 07:25:10 - INFO - modeling_utils:289 -  \n",
                        "=============Loading model from pretrain. kwargs: {'from_tf': False, 'config': {\n",
                        "  \"architectures\": [\n",
                        "    \"BertForMaskedLM\"\n",
                        "  ],\n",
                        "  \"attention_probs_dropout_prob\": 0.1,\n",
                        "  \"directionality\": \"bidi\",\n",
                        "  \"finetuning_task\": null,\n",
                        "  \"hidden_act\": \"gelu\",\n",
                        "  \"hidden_dropout_prob\": 0.1,\n",
                        "  \"hidden_size\": 768,\n",
                        "  \"initializer_range\": 0.02,\n",
                        "  \"intermediate_size\": 3072,\n",
                        "  \"layer_norm_eps\": 1e-12,\n",
                        "  \"loss_type\": \"ce\",\n",
                        "  \"max_position_embeddings\": 512,\n",
                        "  \"model_type\": \"bert\",\n",
                        "  \"num_attention_heads\": 12,\n",
                        "  \"num_hidden_layers\": 12,\n",
                        "  \"num_labels\": 144,\n",
                        "  \"output_attentions\": false,\n",
                        "  \"output_hidden_states\": false,\n",
                        "  \"output_past\": true,\n",
                        "  \"pad_token_id\": 0,\n",
                        "  \"pooler_fc_size\": 768,\n",
                        "  \"pooler_num_attention_heads\": 12,\n",
                        "  \"pooler_num_fc_layers\": 3,\n",
                        "  \"pooler_size_per_head\": 128,\n",
                        "  \"pooler_type\": \"first_token_transform\",\n",
                        "  \"pruned_heads\": {},\n",
                        "  \"torchscript\": false,\n",
                        "  \"type_vocab_size\": 2,\n",
                        "  \"use_bfloat16\": false,\n",
                        "  \"vocab_size\": 21128\n",
                        "}\n",
                        ", 'cache_dir': '/home/haoranhuang/.cache/torch/transformers'}\n",
                        "08/11/2022 07:25:11 - INFO - modeling_utils:357 -  loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin from cache at /home/haoranhuang/.cache/torch/transformers/b1b5e295889f2d0979ede9a78ad9cb5dc6a0e25ab7f9417b315f0a2c22f4683d.929717ca66a3ba9eb9ec2f85973c6398c54c38a4faa464636a491d7a705f7eb6\n",
                        "08/11/2022 07:25:12 - INFO - modeling_utils:425 -  Weights of BertForSentence not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
                        "08/11/2022 07:25:12 - INFO - modeling_utils:428 -  Weights from pretrained model not used in BertForSentence: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
                        "08/11/2022 07:25:12 - INFO - run_sentence_classification:736 -  \n",
                        "========\n",
                        "Training/evaluation parameters Namespace(task_name='sentence', data_dir='/home/haoranhuang/workspace/CLUENER2020/pytorch_version/notebooks/../datasets/sentence', model_type='bert', model_name_or_path='bert-base-chinese', output_dir='/home/haoranhuang/workspace/CLUENER2020/pytorch_version/notebooks/../outputs/bert-base-chinese/sentence_output/bert', markup='bios', loss_type='ce', labels='', config_name='', tokenizer_name='', cache_dir='/home/haoranhuang/.cache/torch/transformers', train_max_seq_length=128, eval_max_seq_length=512, do_train=True, do_eval=True, do_predict=True, evaluate_during_training=False, do_lower_case=True, per_gpu_train_batch_size=24, per_gpu_eval_batch_size=24, gradient_accumulation_steps=1, learning_rate=3e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=4.0, max_steps=-1, warmup_steps=0, logging_steps=224, save_steps=224, eval_all_checkpoints=False, predict_checkpoints=0, no_cuda=False, overwrite_output_dir=True, overwrite_cache=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, server_ip='', server_port='', n_gpu=1, device=device(type='cuda'), id2label={0: 'address', 1: 'book', 2: 'company', 3: 'game', 4: 'government', 5: 'movie', 6: 'name', 7: 'organization', 8: 'position', 9: 'scene', 10: '打车', 11: '地图导航', 12: '免费WIFI', 13: '租车', 14: '同城服务', 15: '快递物流', 16: '婚庆', 17: '家政', 18: '公共交通', 19: '政务', 20: '社区服务', 21: '薅羊毛', 22: '魔幻', 23: '仙侠', 24: '卡牌', 25: '飞行空战', 26: '射击游戏', 27: '休闲益智', 28: '动作类', 29: '体育竞技', 30: '棋牌中心', 31: '经营养成', 32: '策略', 33: 'MOBA', 34: '辅助工具', 35: '约会社交', 36: '即时通讯', 37: '工作社交', 38: '论坛圈子', 39: '婚恋社交', 40: '情侣社交', 41: '社交工具', 42: '生活社交', 43: '微博博客', 44: '新闻', 45: '漫画', 46: '小说', 47: '技术', 48: '教辅', 49: '问答交流', 50: '搞笑', 51: '杂志', 52: '百科', 53: '影视娱乐', 54: '求职', 55: '兼职', 56: '视频', 57: '短视频', 58: '音乐', 59: '直播', 60: '电台', 61: 'K歌', 62: '成人', 63: '中小学', 64: '职考', 65: '公务员', 66: '英语', 67: '视频教育', 68: '高等教育', 69: '成人教育', 70: '艺术', 71: '语言(非英语)', 72: '旅游资讯', 73: '综合预定', 74: '民航', 75: '铁路', 76: '酒店', 77: '行程管理', 78: '民宿短租', 79: '出国', 80: '工具', 81: '亲子儿童', 82: '母婴', 83: '驾校', 84: '违章', 85: '汽车咨询', 86: '汽车交易', 87: '日常养车', 88: '行车辅助', 89: '租房', 90: '买房', 91: '装修家居', 92: '电子产品', 93: '问诊挂号', 94: '养生保健', 95: '医疗服务', 96: '减肥瘦身', 97: '美妆美业', 98: '菜谱', 99: '餐饮店', 100: '体育咨讯', 101: '运动健身', 102: '支付', 103: '保险', 104: '股票', 105: '借贷', 106: '理财', 107: '彩票', 108: '记账', 109: '银行', 110: '美颜', 111: '影像剪辑', 112: '摄影修图', 113: '相机', 114: '绘画', 115: '二手', 116: '电商', 117: '团购', 118: '外卖', 119: '电影票务', 120: '社区超市', 121: '购物咨询', 122: '笔记', 123: '办公', 124: '日程管理', 125: '女性', 126: '经营', 127: '收款', 128: '其他', 129: 'news_story', 130: 'news_culture', 131: 'news_entertainment', 132: 'news_sports', 133: 'news_finance', 134: 'news_house', 135: 'news_car', 136: 'news_edu', 137: 'news_tech', 138: 'news_military', 139: 'news_travel', 140: 'news_world', 141: 'news_stock', 142: 'news_agriculture', 143: 'news_game'}, label2id={'address': 0, 'book': 1, 'company': 2, 'game': 3, 'government': 4, 'movie': 5, 'name': 6, 'organization': 7, 'position': 8, 'scene': 9, '打车': 10, '地图导航': 11, '免费WIFI': 12, '租车': 13, '同城服务': 14, '快递物流': 15, '婚庆': 16, '家政': 17, '公共交通': 18, '政务': 19, '社区服务': 20, '薅羊毛': 21, '魔幻': 22, '仙侠': 23, '卡牌': 24, '飞行空战': 25, '射击游戏': 26, '休闲益智': 27, '动作类': 28, '体育竞技': 29, '棋牌中心': 30, '经营养成': 31, '策略': 32, 'MOBA': 33, '辅助工具': 34, '约会社交': 35, '即时通讯': 36, '工作社交': 37, '论坛圈子': 38, '婚恋社交': 39, '情侣社交': 40, '社交工具': 41, '生活社交': 42, '微博博客': 43, '新闻': 44, '漫画': 45, '小说': 46, '技术': 47, '教辅': 48, '问答交流': 49, '搞笑': 50, '杂志': 51, '百科': 52, '影视娱乐': 53, '求职': 54, '兼职': 55, '视频': 56, '短视频': 57, '音乐': 58, '直播': 59, '电台': 60, 'K歌': 61, '成人': 62, '中小学': 63, '职考': 64, '公务员': 65, '英语': 66, '视频教育': 67, '高等教育': 68, '成人教育': 69, '艺术': 70, '语言(非英语)': 71, '旅游资讯': 72, '综合预定': 73, '民航': 74, '铁路': 75, '酒店': 76, '行程管理': 77, '民宿短租': 78, '出国': 79, '工具': 80, '亲子儿童': 81, '母婴': 82, '驾校': 83, '违章': 84, '汽车咨询': 85, '汽车交易': 86, '日常养车': 87, '行车辅助': 88, '租房': 89, '买房': 90, '装修家居': 91, '电子产品': 92, '问诊挂号': 93, '养生保健': 94, '医疗服务': 95, '减肥瘦身': 96, '美妆美业': 97, '菜谱': 98, '餐饮店': 99, '体育咨讯': 100, '运动健身': 101, '支付': 102, '保险': 103, '股票': 104, '借贷': 105, '理财': 106, '彩票': 107, '记账': 108, '银行': 109, '美颜': 110, '影像剪辑': 111, '摄影修图': 112, '相机': 113, '绘画': 114, '二手': 115, '电商': 116, '团购': 117, '外卖': 118, '电影票务': 119, '社区超市': 120, '购物咨询': 121, '笔记': 122, '办公': 123, '日程管理': 124, '女性': 125, '经营': 126, '收款': 127, '其他': 128, 'news_story': 129, 'news_culture': 130, 'news_entertainment': 131, 'news_sports': 132, 'news_finance': 133, 'news_house': 134, 'news_car': 135, 'news_edu': 136, 'news_tech': 137, 'news_military': 138, 'news_travel': 139, 'news_world': 140, 'news_stock': 141, 'news_agriculture': 142, 'news_game': 143})\n",
                        "========\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "args, config, tokenizer, model, model_classes = setup(\n",
                "    arg_list=arg_list)\n",
                "config_class, model_class, tokenizer_class = model_classes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "686f5344",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def asd(args, task, tokenizer, data_type):\n",
                "    if args.local_rank not in [-1, 0] and not evaluate:\n",
                "        # Make sure only the first process in distributed training process the dataset, and the others will use the cache\n",
                "        torch.distributed.barrier()\n",
                "    processor = processors[task]()\n",
                "    # Load data features from cache or dataset file\n",
                "    feature_dim = args.train_max_seq_length if data_type == 'train' else args.eval_max_seq_length\n",
                "    base_model_name = list(\n",
                "        filter(None, args.model_name_or_path.split('/'))).pop()\n",
                "    cached_features_file = os.path.join(\n",
                "        args.data_dir, f'cached_soft-{data_type}_{base_model_name}_{feature_dim}_{task}')\n",
                "    if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
                "        logger.info(\"Loading features from cached file %s\",\n",
                "                    cached_features_file)\n",
                "        features = torch.load(cached_features_file)\n",
                "    else:\n",
                "        logger.info(\"Creating features from dataset file at %s\", args.data_dir)\n",
                "        label_list = processor.get_labels()\n",
                "        if data_type == 'train':\n",
                "            examples = processor.get_train_examples(args.data_dir)\n",
                "        elif data_type == 'dev':\n",
                "            examples = processor.get_dev_examples(args.data_dir)\n",
                "        else:\n",
                "            examples = processor.get_test_examples(args.data_dir)\n",
                "        features = convert_examples_to_features(examples=examples,\n",
                "                                                tokenizer=tokenizer,\n",
                "                                                label_list=label_list,\n",
                "                                                max_seq_length=args.train_max_seq_length if data_type == 'train'\n",
                "                                                else args.eval_max_seq_length,\n",
                "                                                cls_token_at_end=bool(\n",
                "                                                    args.model_type in [\"xlnet\"]),\n",
                "                                                pad_on_left=bool(\n",
                "                                                    args.model_type in ['xlnet']),\n",
                "                                                cls_token=tokenizer.cls_token,\n",
                "                                                cls_token_segment_id=2 if args.model_type in [\n",
                "                                                    \"xlnet\"] else 0,\n",
                "                                                sep_token=tokenizer.sep_token,\n",
                "                                                # pad on the left for xlnet\n",
                "                                                pad_token=tokenizer.convert_tokens_to_ids(\n",
                "                                                    [tokenizer.pad_token])[0],\n",
                "                                                pad_token_segment_id=4 if args.model_type in [\n",
                "                                                    'xlnet'] else 0,\n",
                "                                                )\n",
                "        if args.local_rank in [-1, 0]:\n",
                "            logger.info(\"Saving features into cached file %s\",\n",
                "                        cached_features_file)\n",
                "            torch.save(features, cached_features_file)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "09c875d7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'/home/haoranhuang/workspace/CLUENER2020/pytorch_version/notebooks/../datasets/sentence'"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "args.data_dir"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8d4ee6d2",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e0ca1d08",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "24d8e2d3",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "027c8f6b",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}